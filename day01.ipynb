{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h1 align=\"center\">PyTorch</h1>\n",
    "\n",
    "1. Tensor Computation\n",
    "2. GPU Acceleration : able to use GPU to speedup calculations\n",
    "3. Dynamic Computing Graph : can change to execution flow during runtime\n",
    "4. Automatic Differentiation\n",
    "5. Distributed Training\n",
    "6. Interoperability with other libraries\n",
    "\n"
   ],
   "id": "bb22d1e067dcc1fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3 align=\"center\">Core PyTorch Modules</h3>\n",
    "\n",
    "- `torch` : the core module providing multidimensional arrays(tensor) and mathematical operations on them.\n",
    "- `torch.autograd` : automatic differentiation engine that records operations on tensor to compute gradients for optimizations.\n",
    "- `torch.nn` : provides the nn library, including layers, activations, loss functions and utilities to build deep learning models.\n",
    "- `torch.optim` : contains optimization algorithms(optimizers) such as SGD, Adam, and RMSprop.\n",
    "- `torch.utils.data` : used for data handling, including Dataset and Dataloader classes for managing and loading datasets efficiently.\n",
    "- `torch.jit` : supports JIT compilation and TorchScript for optimizing models and enabling deployment without Python dependencies.\n",
    "- `torch.distributed` : tolls for distributed training across multiple GPUs and machines, facilitating parallel computation.\n",
    "- `torch.cuda` : interfaces with NVIDIA CUDA to enable GPU acceleration for tensor computations and model training.\n",
    "- `torch.backends `: contains settings and allows control over backend libraries like cuDNN, MKL and other performance tuning.\n",
    "- `torch.multiprocessing` : used for parallelism and multiprocessing similar to python module but with support for CUDA tensors.\n",
    "- `torch.quantization` : tool for model quantization to reduce model size and improve inference speed, especially on edge devices.\n",
    "- `torch.onyx `: support exporting PyTorch models like ONNX(Open Neural Network Exchange) format for interoperability with other frameworks and deployment.\n",
    "\n"
   ],
   "id": "e337a4738c4e7d1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:03:19.608851Z",
     "start_time": "2025-01-30T09:03:19.606932Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "284419688c2d763e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:33:09.099991Z",
     "start_time": "2025-01-29T13:33:09.094865Z"
    }
   },
   "cell_type": "code",
   "source": "torch.__version__",
   "id": "cb875c01633e3850",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:36:28.197773Z",
     "start_time": "2025-01-29T13:36:28.194595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For CUDA device\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.get_device(0))\n",
    "else:\n",
    "    print(\"Nvidia GPU is not available\")\n",
    "\n",
    "# FOR M-Series mac gpu\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(device)\n",
    "else:\n",
    "    print(\"MPS is not available\")\n"
   ],
   "id": "ba06d08660ae1095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia GPU is not available\n",
      "mps\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:36:32.552877Z",
     "start_time": "2025-01-29T13:36:32.544762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tensor can be thought as an n-dimensional array\n",
    "\n",
    "# zero-dimensional tensor : Scalar\n",
    "zero_d_tensor = torch.tensor(0)\n",
    "zero_d_tensor.ndim, zero_d_tensor"
   ],
   "id": "36619516a0894263",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, tensor(0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:36:33.197351Z",
     "start_time": "2025-01-29T13:36:33.192704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one-dimensional tensor : Vector\n",
    "\n",
    "one_d_tensor = torch.tensor([1, 5, 10, 13])\n",
    "one_d_tensor, one_d_tensor.ndim\n"
   ],
   "id": "aa8c1339d8073718",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  5, 10, 13]), 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:36:34.032484Z",
     "start_time": "2025-01-29T13:36:34.028333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# two-dimensional tensor: Matrix\n",
    "\n",
    "# grayscale image can be represented as a 2D tensor where each entry corresponds to the pixel intensity(0-255)\n",
    "two_d_tensor = torch.tensor([\n",
    "    [0, 255,128],\n",
    "    [34, 90, 180]\n",
    "])\n",
    "\n",
    "two_d_tensor, two_d_tensor.ndim"
   ],
   "id": "27d54a89da1fcbda",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0, 255, 128],\n",
       "         [ 34,  90, 180]]),\n",
       " 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:36:34.819123Z",
     "start_time": "2025-01-29T13:36:34.814717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# three-dimensional tensor: RGB Image\n",
    "three_d_tensor = torch.tensor([\n",
    "    [\n",
    "        [0, 255,128],\n",
    "        [0, 255,128],\n",
    "        [0, 255,128]\n",
    "    ]\n",
    "], dtype=torch.uint8)\n",
    "\n",
    "three_d_tensor, three_d_tensor.ndim"
   ],
   "id": "2fc75925dfc3f655",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  0, 255, 128],\n",
       "          [  0, 255, 128],\n",
       "          [  0, 255, 128]]], dtype=torch.uint8),\n",
       " 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:36:35.684851Z",
     "start_time": "2025-01-29T13:36:35.679598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# four-dimensional : Batches of RGB images\n",
    "\n",
    "four_d_tensor = torch.tensor([[\n",
    "    [\n",
    "        [0, 255,128],\n",
    "        [0, 255,128],\n",
    "        [0, 255,128]\n",
    "    ]\n",
    "]], dtype=torch.uint8)\n",
    "four_d_tensor, four_d_tensor.ndim"
   ],
   "id": "8cf99f507695daa9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0, 255, 128],\n",
       "           [  0, 255, 128],\n",
       "           [  0, 255, 128]]]], dtype=torch.uint8),\n",
       " 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tensor are useful because:\n",
    "\n",
    "- Mathematical Operations : linear algebraic operations\n",
    "- Representation of real-world data as a tensor\n",
    "- Can be run on gpu and can be parallelized\n",
    "\n",
    "Tensor used in DL:\n",
    "\n",
    "- Data Storage\n",
    "- Weight and Biases\n",
    "- Matrix Operations\n",
    "- Training Process :\n",
    "    -  Forward pass in DL : z(xTw + b) , gradients during backward pass\n"
   ],
   "id": "15972bf877e85c74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:37:46.150612Z",
     "start_time": "2025-01-29T13:37:46.148056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check type of tensor\n",
    "\n",
    "one_d_tensor.dtype"
   ],
   "id": "e046219450886e42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:37:43.831285Z",
     "start_time": "2025-01-29T13:37:43.828777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# size of tensor\n",
    "\n",
    "one_d_tensor.size()"
   ],
   "id": "13a1afd5f73072a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:41:28.552309Z",
     "start_time": "2025-01-29T13:41:28.548796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using empty\n",
    "\n",
    "empty_tensor = torch.empty(size=(2,3))\n",
    "print(empty_tensor)\n"
   ],
   "id": "a4105c3b1f99eb5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:43:33.486310Z",
     "start_time": "2025-01-29T13:43:33.483300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# zeros tensor : all the entries of tensor are 0\n",
    "\n",
    "zero_tensor = torch.zeros(size=(5,5))\n",
    "print(zero_tensor)\n",
    "\n",
    "zero_tensor.dtype, zero_tensor.size()"
   ],
   "id": "f2538cafe9bb2d55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.Size([5, 5]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:44:32.999535Z",
     "start_time": "2025-01-29T13:44:32.995948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ones tensor : all the entries of tensor are 1\n",
    "\n",
    "ones_tensor = torch.ones(size=(5,5))\n",
    "print(ones_tensor)"
   ],
   "id": "918ec24d091038f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By default the data  type in tensor is : `float32`",
   "id": "1ea0873a1597adf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:51:33.337552Z",
     "start_time": "2025-01-29T13:51:33.334063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rand tensor: entries of the tensor contains randon number between 0 and 1\n",
    "\n",
    "random_tensor = torch.rand(size=(5,5))\n",
    "print(random_tensor)\n",
    "\n",
    "random_tensor.dtype, random_tensor.size()\n",
    "print(\"rand(): picks the values(0 to 1) from randomly from uniform distribution.\")"
   ],
   "id": "959afde6f45eb09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1182, 0.3628, 0.3302, 0.2807, 0.8269],\n",
      "        [0.7934, 0.1577, 0.6951, 0.9363, 0.3530],\n",
      "        [0.7394, 0.1078, 0.1731, 0.1845, 0.5970],\n",
      "        [0.0264, 0.5525, 0.9674, 0.8975, 0.6987],\n",
      "        [0.2962, 0.7868, 0.6388, 0.3797, 0.8793]])\n",
      "rand(): picks the values(0 to 1) from randomly from uniform distribution.\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Linearly Spaced Tensor : one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive.",
   "id": "24f718e50c7d93b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T13:55:52.235637Z",
     "start_time": "2025-01-29T13:55:52.231194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linearly_spaced_tensor = torch.linspace(start=0, end=10, steps=5)\n",
    "linearly_spaced_tensor"
   ],
   "id": "bd8082ffb17e046",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Seeding",
   "id": "236a96cfd47616a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:02:10.088014Z",
     "start_time": "2025-01-29T14:02:10.081374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tensor entries will be same\n",
    "torch.manual_seed(0)\n",
    "\n",
    "rand_t_seed_0 = torch.rand(size=(5,5))\n",
    "print(rand_t_seed_0)\n"
   ],
   "id": "88603b6d97ad224f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
      "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
      "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
      "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]])\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:02:18.853988Z",
     "start_time": "2025-01-29T14:02:18.849563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rand_t_seed_0 = torch.rand(size=(5,5))\n",
    "print(rand_t_seed_0)"
   ],
   "id": "7ba6585635b1317b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
      "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
      "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
      "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]])\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating Custom Tensors",
   "id": "baeb6c3b4ee14afe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:04:49.567161Z",
     "start_time": "2025-01-29T14:04:49.563831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr = [[12, 3, 45], [4,66, 3]]\n",
    "\n",
    "arr_to_tensor = torch.tensor(arr, dtype=torch.float32)\n",
    "print(arr_to_tensor), type(arr_to_tensor)"
   ],
   "id": "104fde29328064e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.,  3., 45.],\n",
      "        [ 4., 66.,  3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, torch.Tensor)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Identity Matrix",
   "id": "5722166a1e9661b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:13:15.903244Z",
     "start_time": "2025-01-29T14:13:15.899082Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "execution_count": 116,
   "source": [
    "# diagonal tensor\n",
    "\n",
    "default_diag_tensor = torch.eye(3,3)\n",
    "print(default_diag_tensor)\n"
   ],
   "id": "20529d93b3770512"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:14:01.474902Z",
     "start_time": "2025-01-29T14:14:01.472006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the diagonal values\n",
    "x = torch.rand(3,3)\n",
    "print(x)\n",
    "\n",
    "diagonal_values = torch.diag(x)\n",
    "print(diagonal_values)"
   ],
   "id": "458dec6823b52f76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8579, 0.6870, 0.0051],\n",
      "        [0.1757, 0.7497, 0.6047],\n",
      "        [0.1100, 0.2121, 0.9704]])\n",
      "tensor([0.8579, 0.7497, 0.9704])\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:16:44.112803Z",
     "start_time": "2025-01-29T14:16:44.109893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# homogenous tensor\n",
    "\n",
    "homogenous_tensor = torch.full((3,3), 5)\n",
    "print(homogenous_tensor)\n",
    "\n",
    "homogenous_tensor_2 = torch.full((3,3), 10.0)\n",
    "print(homogenous_tensor_2)"
   ],
   "id": "5c06328aed8b02b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 5, 5],\n",
      "        [5, 5, 5],\n",
      "        [5, 5, 5]])\n",
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.],\n",
      "        [10., 10., 10.]])\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating a tensor with range",
   "id": "8da059d7d9490d1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:18:44.041482Z",
     "start_time": "2025-01-29T14:18:44.037694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "range_tensor = torch.arange(0, 10, 2, dtype=torch.float32)\n",
    "print(range_tensor)"
   ],
   "id": "cfb09d560f7f5dd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4., 6., 8.])\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tensor Shapes",
   "id": "62a4b7be18ea2e63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:24:21.767959Z",
     "start_time": "2025-01-29T14:24:21.762810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = torch.rand(5,5)\n",
    "print(x1)\n",
    "x1.shape"
   ],
   "id": "92e8d25271ae83e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0780, 0.3986, 0.7742, 0.7703, 0.0178],\n",
      "        [0.8119, 0.1087, 0.3943, 0.2973, 0.4037],\n",
      "        [0.4018, 0.0513, 0.0683, 0.4218, 0.5065],\n",
      "        [0.2729, 0.6883, 0.0500, 0.4663, 0.9397],\n",
      "        [0.2961, 0.9515, 0.6811, 0.0488, 0.8163]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:26:23.841390Z",
     "start_time": "2025-01-29T14:26:23.834879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# want to create a tensor with same shape as x1\n",
    "same_shape_as_x1 = torch.empty(x1.shape)\n",
    "print(same_shape_as_x1)\n",
    "\n",
    "print(torch.full_like(x1, 5))\n",
    "print(torch.zeros_like(x1))\n",
    "print(torch.ones_like(x1))"
   ],
   "id": "3b0d1d9d02e430a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[5., 5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5., 5.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Copying Tensor",
   "id": "e9f83a4f364f0868"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:33:46.414857Z",
     "start_time": "2025-01-29T14:33:46.409789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shallow copy\n",
    "\n",
    "x2 = x1\n",
    "print(x2)\n",
    "\n",
    "print(hash(x1) == hash(x2))\n",
    "\n",
    "x3 = torch.tensor(x1)\n",
    "print(x3)\n",
    "\n",
    "print(hash(x1) == hash(x3))"
   ],
   "id": "5ac3048e3e506f3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0780, 0.3986, 0.7742, 0.7703, 0.0178],\n",
      "        [0.8119, 0.1087, 0.3943, 0.2973, 0.4037],\n",
      "        [0.4018, 0.0513, 0.0683, 0.4218, 0.5065],\n",
      "        [0.2729, 0.6883, 0.0500, 0.4663, 0.9397],\n",
      "        [0.2961, 0.9515, 0.6811, 0.0488, 0.8163]])\n",
      "True\n",
      "tensor([[0.0780, 0.3986, 0.7742, 0.7703, 0.0178],\n",
      "        [0.8119, 0.1087, 0.3943, 0.2973, 0.4037],\n",
      "        [0.4018, 0.0513, 0.0683, 0.4218, 0.5065],\n",
      "        [0.2729, 0.6883, 0.0500, 0.4663, 0.9397],\n",
      "        [0.2961, 0.9515, 0.6811, 0.0488, 0.8163]])\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/vys765k90y9gn_dw0h3w0z5h0000gn/T/ipykernel_28365/4251606690.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x3 = torch.tensor(x1)\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T14:34:20.795098Z",
     "start_time": "2025-01-29T14:34:20.791963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# deep copy : true copy\n",
    "\n",
    "x2 = x1.clone().detach()\n",
    "print(x2)\n",
    "\n",
    "print(hash(x1) == hash(x2))"
   ],
   "id": "5952303d16f1a25a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0780, 0.3986, 0.7742, 0.7703, 0.0178],\n",
      "        [0.8119, 0.1087, 0.3943, 0.2973, 0.4037],\n",
      "        [0.4018, 0.0513, 0.0683, 0.4218, 0.5065],\n",
      "        [0.2729, 0.6883, 0.0500, 0.4663, 0.9397],\n",
      "        [0.2961, 0.9515, 0.6811, 0.0488, 0.8163]])\n",
      "False\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tensor Mathematical Operations",
   "id": "c143c1b747436ab1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:06:13.328597Z",
     "start_time": "2025-01-30T09:06:13.324731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randint(0, 10, (1,5))\n",
    "y = torch.randint(10, 20, (1,5))\n",
    "print(\"X \", x)\n",
    "print(\"Y \", y)\n",
    "print( x + y )"
   ],
   "id": "20f96c694374e812",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X  tensor([[3, 2, 2, 7, 9]])\n",
      "Y  tensor([[12, 14, 12, 18, 12]])\n",
      "tensor([[15, 16, 14, 25, 21]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:06:26.566417Z",
     "start_time": "2025-01-30T09:06:26.563052Z"
    }
   },
   "cell_type": "code",
   "source": "print( x - y )",
   "id": "1b05bd710b7a0676",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -9, -12, -10, -11,  -3]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:06:37.126085Z",
     "start_time": "2025-01-30T09:06:37.123526Z"
    }
   },
   "cell_type": "code",
   "source": "print( x * y )",
   "id": "9cf3675c06bf06d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 36,  28,  24, 126, 108]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:06:59.113649Z",
     "start_time": "2025-01-30T09:06:59.110857Z"
    }
   },
   "cell_type": "code",
   "source": "print( x / y )",
   "id": "ae6de21ff92ce3e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.1429, 0.1667, 0.3889, 0.7500]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:08:35.030850Z",
     "start_time": "2025-01-30T09:08:35.027849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# returns 1 if not divisible by 2 else returns 0\n",
    "print(x % 2)"
   ],
   "id": "9fa6739335571345",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 1, 1]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:11:02.119459Z",
     "start_time": "2025-01-30T09:11:02.115455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transpose\n",
    "print(\"Before transpose: \", x)\n",
    "transpose_x = x.T\n",
    "print(transpose_x)\n",
    "\n",
    "print(x.shape, transpose_x.shape)"
   ],
   "id": "f0b18870af7b7274",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transpose:  tensor([[3, 2, 2, 7, 9]])\n",
      "tensor([[3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [7],\n",
      "        [9]])\n",
      "torch.Size([1, 5]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:15:44.182276Z",
     "start_time": "2025-01-30T09:15:44.178494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "matrix = torch.randint(0, 5, (3,3))\n",
    "print(matrix)\n",
    "\n",
    "v = torch.tensor([-1, 0, 1])\n",
    "\n",
    "res = torch.matmul(matrix, v)\n",
    "print(\"Res: \", res)"
   ],
   "id": "a0ab31138975c579",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4, 2],\n",
      "        [0, 0, 2],\n",
      "        [1, 2, 4]])\n",
      "Res:  tensor([0, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:14:21.952703Z",
     "start_time": "2025-01-30T09:14:21.950649Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "77df365f75aff534",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
