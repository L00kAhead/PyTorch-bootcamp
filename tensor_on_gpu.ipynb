{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T11:10:06.636294Z",
     "start_time": "2025-01-30T11:10:05.719675Z"
    }
   },
   "source": [
    "import torch\n",
    "from mistune.plugins.speedup import speedup\n",
    "from requests import delete"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:13:04.689025Z",
     "start_time": "2025-01-30T11:13:04.686015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apple M-Series GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "id": "99caadcb39924f71",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:13:10.540660Z",
     "start_time": "2025-01-30T11:13:10.535903Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "id": "a4e102e2786812fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating tensor directly on GPU",
   "id": "61a69f5d35dc1aad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:26:33.118132Z",
     "start_time": "2025-01-30T11:26:32.137591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_on_gpu = torch.randn((1,100), device=device)\n",
    "print(tensor_on_gpu)"
   ],
   "id": "50b8404ef302008a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6906,  0.6685,  0.5140,  1.1113, -0.4885, -0.8072, -0.1593,  0.3866,\n",
      "          0.7595, -0.7832,  0.4473, -0.5006,  0.6245,  1.5383,  0.1674,  1.5041,\n",
      "         -1.8178, -0.5112, -0.2424,  1.7457, -0.4926,  0.8301, -1.2572,  2.0500,\n",
      "         -0.2235,  1.7821, -0.9370, -0.1011, -1.8279, -0.1539,  1.3939,  0.5859,\n",
      "          0.3556, -0.1198,  0.4467, -0.6744,  0.6330,  0.4523, -0.8398,  1.3423,\n",
      "         -0.5747, -0.4229,  0.2360, -0.6424,  0.5872,  1.0378, -0.2401,  0.4329,\n",
      "          0.2897,  0.8019,  0.8613, -1.9732, -0.2761,  0.2811,  0.4771,  0.1949,\n",
      "         -0.7711,  0.0787,  0.5961,  1.0704, -0.7727, -0.5376, -0.7488,  0.0812,\n",
      "          0.7178,  2.1007, -0.3433,  0.3104, -0.2520, -0.0679, -0.3219, -0.0056,\n",
      "          0.9772,  1.3820,  0.9785,  0.9086, -0.0399,  1.0835, -0.5574,  0.0371,\n",
      "         -0.5121,  1.0380, -1.2688,  0.6838,  0.0393,  0.1016, -0.1701, -0.1640,\n",
      "          1.5495, -0.7094, -0.7630, -1.8333, -1.2743, -1.3693, -1.5351, -0.4042,\n",
      "         -0.9915, -0.1157, -0.3197, -0.7775]], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the tensor from CPU to GPU",
   "id": "716d6a5ae59990a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:26:35.672722Z",
     "start_time": "2025-01-30T11:26:35.667610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_on_cpu = torch.randn(1,100)\n",
    "print(tensor_on_cpu)"
   ],
   "id": "119d061e8bd98829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2866,  0.6810,  0.7856, -0.9897,  0.3217, -1.2076, -0.4931, -1.5623,\n",
      "         -0.9995, -0.5288,  0.1305,  1.8685,  0.0364,  1.1974, -0.0867, -0.3482,\n",
      "          0.3900,  0.9182, -0.1606, -1.4434,  0.1818, -0.4112,  1.8491, -0.2412,\n",
      "         -0.8175, -1.5244, -0.2964, -1.5349, -0.3892,  0.8344,  1.4887, -0.6923,\n",
      "          0.7511, -0.0296, -0.5557,  0.9183, -0.5913, -1.1816, -0.1183,  1.5848,\n",
      "         -0.8017, -0.0156,  0.0130,  0.2284, -0.3615,  1.0280, -0.6735, -0.8081,\n",
      "          1.5538, -0.2224,  0.5608, -1.0810, -1.1300,  0.9732,  0.1275, -1.2171,\n",
      "          1.7618,  0.7645, -1.8044,  0.5261,  0.0326,  0.1956,  0.5222,  0.6699,\n",
      "         -0.7333, -0.9613, -0.2635, -2.1884, -0.6788, -0.0138, -0.8783, -1.4675,\n",
      "          0.7742,  0.7288, -0.3964, -0.1791,  0.9307, -1.2816, -1.8383, -0.4697,\n",
      "          1.4614,  0.4369,  0.0638, -0.2479,  0.7006, -0.9237,  0.3558,  0.1841,\n",
      "         -0.4641, -0.5300,  0.5422, -0.1667,  0.4780, -0.6419,  0.5543, -1.5321,\n",
      "          0.7398, -1.1497,  0.5708, -0.2797]])\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:26:48.989031Z",
     "start_time": "2025-01-30T11:26:48.948228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the tensor from cpu to gpu\n",
    "\n",
    "c = tensor_on_cpu.to(device)\n",
    "print(c)"
   ],
   "id": "7fa7c911a7af3a2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2866,  0.6810,  0.7856, -0.9897,  0.3217, -1.2076, -0.4931, -1.5623,\n",
      "         -0.9995, -0.5288,  0.1305,  1.8685,  0.0364,  1.1974, -0.0867, -0.3482,\n",
      "          0.3900,  0.9182, -0.1606, -1.4434,  0.1818, -0.4112,  1.8491, -0.2412,\n",
      "         -0.8175, -1.5244, -0.2964, -1.5349, -0.3892,  0.8344,  1.4887, -0.6923,\n",
      "          0.7511, -0.0296, -0.5557,  0.9183, -0.5913, -1.1816, -0.1183,  1.5848,\n",
      "         -0.8017, -0.0156,  0.0130,  0.2284, -0.3615,  1.0280, -0.6735, -0.8081,\n",
      "          1.5538, -0.2224,  0.5608, -1.0810, -1.1300,  0.9732,  0.1275, -1.2171,\n",
      "          1.7618,  0.7645, -1.8044,  0.5261,  0.0326,  0.1956,  0.5222,  0.6699,\n",
      "         -0.7333, -0.9613, -0.2635, -2.1884, -0.6788, -0.0138, -0.8783, -1.4675,\n",
      "          0.7742,  0.7288, -0.3964, -0.1791,  0.9307, -1.2816, -1.8383, -0.4697,\n",
      "          1.4614,  0.4369,  0.0638, -0.2479,  0.7006, -0.9237,  0.3558,  0.1841,\n",
      "         -0.4641, -0.5300,  0.5422, -0.1667,  0.4780, -0.6419,  0.5543, -1.5321,\n",
      "          0.7398, -1.1497,  0.5708, -0.2797]], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:28:57.380839Z",
     "start_time": "2025-01-30T11:28:57.272773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_gpu = torch.randn((1000,1000), device=device)\n",
    "y_gpu = torch.randn((1000,1000), device=device)"
   ],
   "id": "ff03124aeaddac2a",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:33:13.343844Z",
     "start_time": "2025-01-30T11:33:09.042933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "res = torch.matmul(x_gpu, y_gpu)"
   ],
   "id": "26173b00fdf7e034",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 μs ± 1.16 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:29:32.245983Z",
     "start_time": "2025-01-30T11:29:32.214907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_cpu = torch.randn((1000,1000))\n",
    "y_cpu = torch.randn((1000,1000))"
   ],
   "id": "fa25bacea62e5fc1",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:33:30.639662Z",
     "start_time": "2025-01-30T11:33:22.213189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "r = torch.matmul(x_cpu, y_cpu)"
   ],
   "id": "dabc1b8bf059627d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 ms ± 29 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:35:26.086985Z",
     "start_time": "2025-01-30T11:35:26.085013Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"GPU speedup : \", 1.03/0.558)",
   "id": "5f6241b90ce338d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU speedup :  1.8458781362007166\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As the data size grows the GPU will outperform the CPU by ~100x",
   "id": "6b19313c69901ba7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a52ac0b367e2cacb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
